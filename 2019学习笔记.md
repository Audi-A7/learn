# 2019学习笔记

标题
==

标签（空格分隔）： presto hive mongDB 响应式编程 spring的状态机 缓存相关

---

presto参考文档：

 1. https://tech.meituan.com/2014/06/16/presto.html
 2. http://www.stay-stupid.com/?p=395
 

hive参考文档：

 1. https://blog.csdn.net/wangyang1354/article/details/50570903
 2. https://blog.csdn.net/LW_GHY/article/details/51469753
 3. https://www.jianshu.com/p/dbad3b3d40eb

MongoDB参考文档：

 1. https://www.w3cschool.cn/mongodb/mongodb-query.html
 

spring5的webflux参考资料：

 1. https://juejin.im/post/5b3a22a16fb9a024db5ff13e
 2. https://zhuanlan.zhihu.com/p/37846655
 3. https://github.com/pkpk1234/learn-reactor
 

spring的状态机参考资料：

 1. http://blog.didispace.com/spring-statemachine/
 


缓存相关参考资料：

2. http://zhuanlan.51cto.com/art/201806/577116.htm
3. https://tech.meituan.com/2017/03/17/cache-about.html


poi生成pdf文档：

 1. https://blog.csdn.net/makang456/article/details/70161037
 

mysql间歇锁
--------

https://blog.csdn.net/andyxm/article/details/44810417
https://zhuanlan.zhihu.com/p/48269420
https://dev.mysql.com/doc/refman/5.7/en/innodb-locking.html#innodb-gap-locks

需要强调一下：间隙锁在**主键索引、普通索引**上的性质略微有些差别。

所谓间隙锁，区别于行锁只锁住一行，间隙锁会锁住一个区间段的数据。

下面先讨论**主键索引**上的间隙锁：

比如：
```mysql
CREATE TABLE `test` (
  `id` int(1) NOT NULL AUTO_INCREMENT,
  `name` varchar(8) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

INSERT INTO `test` VALUES ('1', '小罗');
INSERT INTO `test` VALUES ('5', '小黄');
INSERT INTO `test` VALUES ('7', '小明');
INSERT INTO `test` VALUES ('11', '小红');
```
上面数据存在隐藏的间隙锁：

 1. (-infinity, 1]
 2. (1, 5]
 3. (5, 7]
 4. (7, 11]
 5. (11, +infinity]

然后执行如下的sql语句，会产生间隙锁。
```mysql
/* 开启事务1 */
BEGIN;
/* 查询 id 在 5 - 7 范围的数据并加记录锁 */
SELECT * FROM `test` WHERE `id` BETWEEN 5 AND 7 FOR UPDATE;
/* 延迟30秒执行，防止锁释放 */
SELECT SLEEP(30);

# 注意：以下的语句不是放在一个事务中执行，而是分开多次执行，每次事务中只有一条添加语句

/* 事务2插入一条 id = 3，name = '小张1' 的数据 */
INSERT INTO `test` (`id`, `name`) VALUES (3, '小张1'); # 正常执行

/* 事务3插入一条 id = 4，name = '小白' 的数据 */
INSERT INTO `test` (`id`, `name`) VALUES (4, '小白'); # 正常执行

/* 事务4插入一条 id = 6，name = '小东' 的数据 */
INSERT INTO `test` (`id`, `name`) VALUES (6, '小东'); # 阻塞

/* 事务5插入一条 id = 8， name = '大罗' 的数据 */
INSERT INTO `test` (`id`, `name`) VALUES (8, '大罗'); # 阻塞

/* 事务6插入一条 id = 9， name = '大东' 的数据 */
INSERT INTO `test` (`id`, `name`) VALUES (9, '大东'); # 阻塞

/* 事务7插入一条 id = 11， name = '李西' 的数据 */
INSERT INTO `test` (`id`, `name`) VALUES (11, '李西'); # 阻塞

/* 事务8插入一条 id = 12， name = '张三' 的数据 */
INSERT INTO `test` (`id`, `name`) VALUES (12, '张三'); # 正常执行

/* 提交事务1，释放事务1的锁 */
COMMIT;
```
上面的for update语句锁住了[5-7]、[7-11]**两个区间**的数据！！！

另外。如果for update语句或者delete语句操作的数据在数据库不存在，那么也会产生间隙锁，但是它们只会锁住紧邻的区间。比如，删除id=3的数据（忽略上面事务的sql产生的数据），那么会产生[1-5]的间歇锁。

下面再看一下**普通索引**上的间隙锁：
准备如下表结构及初始数据：
```mysql
# 注意：number 不是唯一值

CREATE TABLE `test1` (
  `id` int(1) NOT NULL AUTO_INCREMENT,
  `number` int(1) NOT NULL COMMENT '数字',
  PRIMARY KEY (`id`),
  KEY `number` (`number`) USING BTREE
) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8;

# 初始化数据
INSERT INTO `test1` VALUES (1, 1);
INSERT INTO `test1` VALUES (5, 3);
INSERT INTO `test1` VALUES (7, 8);
INSERT INTO `test1` VALUES (11, 12);
```
 number 索引存在的隐藏间隙：
 
 1. (-infinity, 1]
 2. (1, 3]
 3. (3, 8]
 4. (8, 12]
 5. (12, +infinity]

然后执行如下的事务：
```mysql
/* 开启事务1 */
BEGIN;
/* 查询 number = 2 的数据并加记录锁 */
SELECT * FROM `test1` WHERE `number` = 2 FOR UPDATE;
/* 延迟30秒执行，防止锁释放 */
SELECT SLEEP(30);

# 注意：以下的语句不是放在一个事务中执行，而是分开多次执行，每次事务中只有一条添加语句

/* 事务2插入一条 number = 0 的数据 */
INSERT INTO `test1` (`number`) VALUES (0); # 正常执行

/* 事务3插入一条 number = 1 的数据 */
INSERT INTO `test1` (`number`) VALUES (1); # 被阻塞

/* 事务4插入一条 number = 2 的数据 */
INSERT INTO `test1` (`number`) VALUES (2); # 被阻塞

/* 事务5插入一条 number = 4 的数据 */
INSERT INTO `test1` (`number`) VALUES (4); # 正常执行

/* 事务6插入一条 number = 8 的数据 */
INSERT INTO `test1` (`number`) VALUES (8); # 正常执行

/* 事务7插入一条 number = 9 的数据 */
INSERT INTO `test1` (`number`) VALUES (9); # 正常执行

/* 事务8插入一条 number = 10 的数据 */
INSERT INTO `test1` (`number`) VALUES (10); # 正常执行

/* 提交事务1 */
COMMIT;
```

可以看到，上面的sql产生number索引了[1-3]的间隙锁。

再看下下面的sql：
```mysql
/* 开启事务1 */
BEGIN;
/* 查询 number = 5 的数据并加记录锁 */
SELECT * FROM `test1` WHERE `number` = 3 FOR UPDATE;
/* 延迟30秒执行，防止锁释放 */
SELECT SLEEP(30);

# 注意：以下的语句不是放在一个事务中执行，而是分开多次执行，每次事务中只有一条添加语句

/* 事务2插入一条 number = 0 的数据 */
INSERT INTO `test1` (`number`) VALUES (0); # 正常执行

/* 事务3插入一条 number = 1 的数据 */
INSERT INTO `test1` (`number`) VALUES (1); # 被阻塞

/* 事务4插入一条 number = 2 的数据 */
INSERT INTO `test1` (`number`) VALUES (2); # 被阻塞

/* 事务5插入一条 number = 4 的数据 */
INSERT INTO `test1` (`number`) VALUES (4); # 被阻塞

/* 事务6插入一条 number = 8 的数据 */
INSERT INTO `test1` (`number`) VALUES (8); # 正常执行

/* 事务7插入一条 number = 9 的数据 */
INSERT INTO `test1` (`number`) VALUES (9); # 正常执行

/* 事务8插入一条 number = 10 的数据 */
INSERT INTO `test1` (`number`) VALUES (10); # 正常执行

/* 提交事务1 */
COMMIT;
```
上面的sql，即便存在number=3的记录，但是还是产生了[1-8]的间隙锁。至于原因，我们先看一下下面的sql再解释:
```java
/* 开启事务1 */
BEGIN;
/* 查询 number = 5 的数据并加记录锁 */
SELECT * FROM `test1` WHERE `number` = 3 FOR UPDATE;
/* 延迟30秒执行，防止锁释放 */
SELECT SLEEP(30);

/* 事务1插入一条 id = 2， number = 1 的数据 */
INSERT INTO `test1` (`id`, `number`) VALUES (2, 1); # 阻塞

/* 事务2插入一条 id = 3， number = 2 的数据 */
INSERT INTO `test1` (`id`, `number`) VALUES (3, 2); # 阻塞

/* 事务3插入一条 id = 6， number = 8 的数据 */
INSERT INTO `test1` (`id`, `number`) VALUES (6, 8); # 阻塞

/* 事务4插入一条 id = 8， number = 8 的数据 */
INSERT INTO `test1` (`id`, `number`) VALUES (8, 8); # 正常执行

/* 事务5插入一条 id = 9， number = 9 的数据 */
INSERT INTO `test1` (`id`, `number`) VALUES (9, 9); # 正常执行

/* 事务6插入一条 id = 10， number = 12 的数据 */
INSERT INTO `test1` (`id`, `number`) VALUES (10, 12); # 正常执行

/* 事务7修改 id = 11， number = 12 的数据 */
UPDATE `test1` SET `number` = 5 WHERE `id` = 11 AND `number` = 12; # 阻塞

/* 提交事务1 */
COMMIT;
```
注意上面的事务3和事务4.事务3阻塞了，事务4却成功了。这是为啥？看看下面这张图：
![此处输入图片的描述][1]
如上图所示，存在原始数据id=7，number=8，因此事务4的id=8，number=8不会被阻塞。

 1. 在普通索引列上，**不管**是何种查询，只要加锁，都会产生间隙锁，这跟唯一索引不一样；
 2. 在普通索引跟唯一索引中，数据间隙的分析，数据行是**优先**根据**普通索引**排序，再根据唯一索引排序。
 4. 临键锁，是记录锁与间隙锁的组合，它的封锁范围，既包含索引记录，又包含索引区间。临键锁的主要目的，也是为了避免幻读(Phantom Read)。如果把事务的隔离级别降级为RC，临键锁则也会失效。


Java的泛型
-------
https://www.toutiao.com/i6728925616785080844/

Java 泛型（generics）是 JDK 5 中引入的一个新特性,泛型提供了编译时类型安全检测机制，该机制允许开发者在编译时检测到非法的类型。泛型的好处就是在编译的时候能够检查类型安全，并且所有的强制转换都是自动和隐式的。

我们在定义泛型类，泛型方法，泛型接口的时候经常会碰见很多不同的通配符，比如 T，E，K，V 等等，这些通配符又都是什么意思呢？

本质上这些个都是通配符，没啥区别，只不过是编码时的一种约定俗成的东西。比如上述代码中的 T ，我们可以换成 A-Z 之间的任何一个 字母都可以，并不会影响程序的正常运行，但是如果换成其他的字母代替 T ，在可读性上可能会弱一些。通常情况下，T，E，K，V，？ 是这样约定的：

 - ？ 表示不确定的 java 类型
 - T (type) 表示具体的一个java类型
 - K V (key value) 分别代表java键值中的Key Value
 - E (element) 代表Element

首先说一下**?**通配符：
![此处输入图片的描述][2]
当调用 countLegs1 时，就会飘红，提示的错误信息如下：
![此处输入图片的描述][3]

所以，对于不确定或者不关心实际要操作的类型，可以使用无限制通配符（尖括号里一个问号，即 <?> ），表示可以持有任何类型。像 countLegs 方法中，限定了**上界**，但是不关心具体类型是什么，所以对于传入的 **Animal** 的所有**子类**都可以支持，并且不会报错。而 countLegs1 就不行。

拼多多面经
-----

https://www.toutiao.com/i6673066864022651396/

tcc事务学习  2pc 3pc 比较
-------

 1. https://blog.csdn.net/u013380694/article/details/83347764
 2. https://www.cnblogs.com/jajian/p/10014145.html
 3. https://juejin.im/post/5bf201f7f265da610f63528a

tcc（try-confirm-Cancel）事务这个东西，个人觉得其实就是一个类似于2pc的分布式事务处理机制。为了达到某种操作（例如商品订单的业务），它并不会直接进行操作，而是有一个预操作的过程（try），如果try成功了，那么才会进行confirm（注意：tcc有一个隐含的设定，try成功以后，那么必须confirm也成功，就好比我们订火车票一样，一旦锁定席位成功，在剩余的15分钟内，只要我们付款，那么一定可以保证出票成功，一样的道理）。如果try失败了，那么才会有cancel这一步。

连接3里使用我们平时都会接触到的订单的业务来讲解，通俗易懂。

一般tcc框架，除非大公司，一般公司都会使用一些开源的框架比如

 1. https://github.com/liuyangming/ByteTCC

ByteTCC可以方便的与springcloud或者dubbo集成。
![此处输入图片的描述][4]
 
 

springcloud部分组件底层原理
-------------------

 
 

springcloud参数调优
---------------

 1. https://juejin.im/post/5be83e166fb9a049a7115580

其实，就如参考文档中说的一样，一般的调优主要分成下面几个方面

 - 数据库做读写分离（甚至分库分表）
 - 调整服务之间调用的超时时间（当然这个也不能太大，否则会导致容器的连接池被占满，从而hang住）
 - 数据库合理配置索引，且不要写「大」sql，复杂的业务处理最好放在java代码中进行，一时降低数据库压力，二是方便后期维护（看java代码总比看sql好吧。。）
 - 配置ribbon的自动重试次数（一般失败后自动重试一次,如下图所示），并且需要进行接口幂等性设置，防止重刷
 - 使用缓存，对于非频繁变化的数据进行缓存，合理设置过期时间（对于redis的key建议参考阿里的redis规范进行设置）

 ![此处输入图片的描述][5]
 

面试经典面经
----

 1. https://juejin.im/post/5d6f0987f265da03cf7aab4f


腾讯面经
----

 1. https://www.toutiao.com/i6628527382590390798/

DispatcherServlet执行流程
---------------------

 1. https://www.jianshu.com/p/0f981efdfbbd
 2. https://www.cnblogs.com/tengyunhao/p/7518481.html

DispatcherServlet执行流程，其实简单来说，无非就是根据url定位到可以处理该请求的controller方法上，然后进行相关处理，然后返回。

详细一点的话就是，DispatcherServlet通过HandlerMapping定位具体的controller类，并且返回HandlerExecutionChain对象，然后根据HandlerExecutionChain定位到具体的执行方法，也就是HandlerAdapter，最后执行完成进行返回。

更详细的可以参考链接1：

![此处输入图片的描述][6]

具体处理过程如下:

1、用户请求发送至DispatcherServlet类进行处理。

2、DispatcherServlet类遍历所有配置的HandlerMapping类请求查找Handler。

3、HandlerMapping类根据request请求的URL等信息查找能够进行处理的Handler，以及相关拦截器interceptor并构造HandlerExecutionChain。

4、HandlerMapping类将构造的HandlerExecutionChain类的对象返回给前端控制器DispatcherServlet类。

5、前端控制器拿着上一步的Handler遍历所有配置的HandlerAdapter类请求执行Handler。

6、HandlerAdapter类执行相关Handler并获取ModelAndView类的对象。

7、HandlerAdapter类将上一步Handler执行结果的ModelAndView 类的对象返回给前端控制器。

8、DispatcherServlet类遍历所有配置的ViewResolver类请求进行视图解析。

9、ViewResolver类进行视图解析并获取View对象。

10、ViewResolver类向前端控制器返回上一步骤的View对象。

11、DispatcherServlet类进行视图View的渲染，填充Model。

12、DispatcherServlet类向用户返回响应。

主流Java数据库连接池分析
--------------

 1. https://www.toutiao.com/i6551532416505217539/

常用的主流开源数据库连接池有C3P0、DBCP、Tomcat Jdbc Pool、BoneCP、Druid等。

**C3p0**: 开源的JDBC连接池，实现了数据源和JNDI绑定，支持JDBC3规范和JDBC2的标准扩展。目前使用它的开源项目有Hibernate、Spring等。单线程，性能较差，适用于小型系统，代码600KB左右。

**DBCP (Database Connection Pool)**:由Apache开发的一个Java数据库连接池项目， Jakarta commons-pool对象池机制，Tomcat使用的连接池组件就是DBCP。单独使用dbcp需要3个包：common-dbcp.jar,common-pool.jar,common-collections.jar，预先将数据库连接放在内存中，应用程序需要建立数据库连接时直接到连接池中申请一个就行，用完再放回。单线程，并发量低，性能不好，适用于小型系统。

**Tomcat Jdbc Pool**：Tomcat在7.0以前都是使用common-dbcp做为连接池组件，但是dbcp是单线程，为保证线程安全会锁整个连接池，性能较差，dbcp有超过60个类，也相对复杂。Tomcat从7.0开始引入了新增连接池模块叫做Tomcat jdbc pool，基于Tomcat JULI，使用Tomcat日志框架，完全兼容dbcp，通过异步方式获取连接，支持高并发应用环境，超级简单核心文件只有8个，支持JMX，支持XA Connection。

**BoneCP**：官方说法BoneCP是一个高效、免费、开源的Java数据库连接池实现库。设计初衷就是为了提高数据库连接池性能，根据某些测试数据显示，BoneCP的速度是最快的，要比当时第二快速的连接池快25倍左右，完美集成到一些持久化产品如Hibernate和DataNucleus中。BoneCP特色：高度可扩展，快速；连接状态切换的回调机制；允许直接访问连接；自动化重置能力；JMX支持；懒加载能力；支持XML和属性文件配置方式；较好的Java代码组织，100%单元测试分支代码覆盖率；代码40KB左右。

**Druid**：Druid是Java语言中最好的数据库连接池，Druid能够提供强大的监控和扩展功能，是一个可用于大数据实时查询和分析的高容错、高性能的开源分布式系统，尤其是当发生代码部署、机器故障以及其他产品系统遇到宕机等情况时，Druid仍能够保持100%正常运行。主要特色：为分析监控设计；快速的交互式查询；高可用；可扩展；Druid是一个开源项目，源码托管在github上。

主流连接池各项功能对比如下：

![此处输入图片的描述][7]

HikariCP与其他数据库连接池的对比：

![此处输入图片的描述][8]

**HikariCP性能分析：**

 1. HikariCP通过优化(concurrentBag，fastStatementList )集合来提高并发的读写效率。
 2. HikariCP使用threadlocal缓存连接及大量使用CAS的机制，最大限度的避免lock。但可能带来cpu使用率的上升（因为cas会有while循环）。
 3. 从字节码的维度优化代码。 (default inline threshold for a JVM running the server
    Hotspot compiler is 35 bytecodes ）让方法尽量在35个字节码一下，来提升jvm的处理效率。

 

OOM的常见情况
--------

 1. https://monkeysayhi.github.io/2018/11/05/Java%E4%B8%AD%E7%9A%84%E5%B8%B8%E8%A7%81OOM%E5%8F%8A%E5%8E%9F%E5%9B%A0/
 2. https://www.jianshu.com/p/2fdee831ed03

**堆内存溢出**

这应该是我们最为常见的一种OOM，当堆内没有足够的内存供申请对象使用时，就会出现，示例代码如下：
```java
  public static void main(String args[]) throws Exception {
        UserController userController = new UserController();
        List list = new ArrayList();
        while (true) {
            list.add(userController);
        }
    }
```

运行输出：
```java
Exception in thread "main" java.lang.OutOfMemoryError: Java heap space
	at java.util.Arrays.copyOf(Arrays.java:3210)
	at java.util.Arrays.copyOf(Arrays.java:3181)
	at java.util.ArrayList.grow(ArrayList.java:265)
	at java.util.ArrayList.ensureExplicitCapacity(ArrayList.java:239)
	at java.util.ArrayList.ensureCapacityInternal(ArrayList.java:231)
	at java.util.ArrayList.add(ArrayList.java:462)
	at com.t4f.gaea.sample.controller.UserNormalController.main(UserNormalController.java:47)
```

**java.lang.OutOfMemoryError:GC overhead limit exceeded**

当应用程序花费超过98%的时间用来做GC并且回收了不到2%的堆内存时，会抛出java.lang.OutOfMemoryError:GC overhead limit exceeded错误。具体的表现就是你的应用几乎耗尽所有可用内存，并且GC多次均未能清理干净。示例代码如下：
```java
 public static void main(String args[]) throws Exception {
        Map map = new HashMap();
        Random r = new Random();
        while (true) {
            map.put(r.nextInt(), "value");
        }
    }
```

注意设置JVM参数：
```java
-Xmx10m -XX:+UseParallelGC
```
运行输出：
```java
Exception in thread "main" java.lang.OutOfMemoryError: GC overhead limit exceeded
	at java.lang.Integer.valueOf(Integer.java:832)
	at com.t4f.gaea.sample.controller.UserNormalController.main(UserNormalController.java:48)
```
 需要注意的是 ，上面的错误信息跟GC算法有很大关系，如果是以G1收集器的话，那么输出如下：
 ```java
 Exception in thread "main" java.lang.OutOfMemoryError: Java heap space
	at java.util.HashMap.newNode(HashMap.java:1750)
	at java.util.HashMap.putVal(HashMap.java:631)
	at java.util.HashMap.put(HashMap.java:612)
	at com.t4f.gaea.sample.controller.UserNormalController.main(UserNormalController.java:48)
 ```
 
 **java.lang.OutOfMemoryError:Metaspace**
 
 元数据区溢出，示例代码如下：
 ```java
     public static Class generate(String name) throws Exception {
        ClassPool pool = ClassPool.getDefault();
        return pool.makeClass(name).toClass();
    }

    public static void main(String args[]) throws Exception {
        for (int i = 0; ; i++) {
            generate("com.audi" + i);
        }
    }
 ```
 需要设置虚拟机参数，-XX：MaxMetaspaceSize = 32m，否则可能元数据区在内存中，可能内存还没耗完，堆内存就先溢出了。
 
 输出如下：
 ```java
Exception in thread "main" org.apache.ibatis.javassist.CannotCompileException: by java.lang.OutOfMemoryError: Compressed class space
	at org.apache.ibatis.javassist.util.proxy.DefineClassHelper.toClass2(DefineClassHelper.java:140)
	at org.apache.ibatis.javassist.util.proxy.DefineClassHelper.toClass(DefineClassHelper.java:95)
	at org.apache.ibatis.javassist.ClassPool.toClass(ClassPool.java:1143)
	at org.apache.ibatis.javassist.ClassPool.toClass(ClassPool.java:1106)
 ```
 
 **栈溢出**
 递归调用，如果没有break的话，最容易出现栈溢出，示例代码如下：
 ```java
    
    private static void rec(){
        rec();
        return;
   }

    public static void main(String args[]) throws Exception {
        for (int i = 0; ; i++) {
            rec();
        }
    }
 ```
 

Redis的缓存过期策略和内存淘汰策略
-------------------
https://www.jianshu.com/p/8aa619933ebb

Redis的缓存过期策略和内存淘汰策略，是两个完全不同的东西，**过期策略**讲的是缓存key到期了，redis该如何处理这些数据；而**淘汰策略**讲的是redis内存不足时，redis该如何为新插入的数据申请内存空间。

 - Redis的过期策略

过期策略通常有以下三种：

**定时过期**：每个设置过期时间的key都需要创建一个定时器，到过期时间就会立即清除。该策略可以立即清除过期的数据，对内存很友好；但是会占用大量的CPU资源去处理过期的数据，从而影响缓存的响应时间和吞吐量。

**惰性过期**：只有当访问一个key时，才会判断该key是否已过期，过期则清除。该策略可以最大化地节省CPU资源，却对内存非常不友好。极端情况可能出现大量的过期key没有再次被访问，从而不会被清除，占用大量内存。

**定期过期**：每隔一定的时间，会扫描一定数量的数据库的expires字典中一定数量的key，并清除其中已过期的key。该策略是前两者的一个折中方案。通过调整定时扫描的时间间隔和每次扫描的限定耗时，可以在不同情况下使得CPU和内存资源达到最优的平衡效果。
(expires字典会保存所有设置了过期时间的key的过期时间数据，其中，key是指向键空间中的某个键的指针，value是该键的毫秒精度的UNIX时间戳表示的过期时间。键空间是指该Redis集群中保存的所有键。)

Redis中同时使用了**惰性**过期和**定期**过期两种过期策略。

 - Redis的内存淘汰策略

Redis的内存淘汰策略是指在Redis的用于缓存的内存不足时，怎么处理需要新写入且需要申请额外空间的数据。

 1. noeviction：当内存不足以容纳新写入数据时，新写入操作会报错。
 2. allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key。
 3. allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个key。
 4. volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key。
 5. volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key。
 6. volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除。

rpc通信和http通信的区别联系
-----------------

 1. https://www.zhihu.com/question/41609070
 2. https://www.cnblogs.com/winner-0715/p/5847638.html
 3. https://blog.csdn.net/MOU_IT/article/details/79873612

个人总结来看，其实就是rpc协议相对来说，更加灵活，它可以直接建立在tcp之上，也可以建立在http协议之上。但是http不行，它必须遵循特定的规范，且每次请求附加的冗余信息较多。比如下面是一个典型的http响应报文格式：
```html
HTTP/1.0 200 OK 
Content-Type: text/plain
Content-Length: 137582
Expires: Thu, 05 Dec 1997 16:00:00 GMT
Last-Modified: Wed, 5 August 1996 15:55:28 GMT
Server: Apache 0.84

<html>
  <body>Hello World</body>
</html>
```
与之对比，由于rpc可以自定义交互格式，假如定义成如下格式：
![此处输入图片的描述][9]

可以明显看出，在一次交互过程中，rpc传输的冗余信息更少。在带宽一定的条件下，效率相对会更高（这一般都是针对http1.1而言）。

http2.0版本已经针对http协议本身进行了大幅的优化，比如支持并发请求服务器，下面会进行介绍。

http2.0协议
---------

二进制协议与文本协议
----------


 
 
 
 
 
 
 
 
 


  [1]: https://github.com/WQZ321123/learn/blob/master/image/mysql/%E6%99%AE%E9%80%9A%E7%B4%A2%E5%BC%95%E7%9A%84%E9%97%B4%E9%9A%99%E9%94%81.jpg?raw=true
  [2]: https://github.com/Audi-A7/learn/blob/master/image/other/%E9%97%AE%E5%A5%BD%E9%80%9A%E9%85%8D%E7%AC%A6.jpg?raw=true
  [3]: https://github.com/Audi-A7/learn/blob/master/image/other/error.jpg?raw=true
  [4]: https://github.com/Audi-A7/learn/blob/master/image/2019/ByteTCC.png?raw=true
  [5]: https://github.com/Audi-A7/learn/blob/master/image/2019/ribbon_auto_retry.png?raw=true
  [6]: https://raw.githubusercontent.com/Audi-A7/learn/master/image/2019/dispatcherServlet.webp?token=ABXI2UIEHF4VBVTMDBAGLX25RIIJQ
  [7]: https://github.com/Audi-A7/learn/blob/master/image/2019/connector.jpg?raw=true
  [8]: https://github.com/Audi-A7/learn/blob/master/image/2019/connector2.jpg?raw=true
  [9]: https://github.com/Audi-A7/learn/blob/master/image/2019/rpc.jpg?raw=true